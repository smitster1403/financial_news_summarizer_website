name: Daily News Scraping

on:
  schedule:
    # Run at 6:06 AM UTC daily
    - cron: '6 6 * * *'
  workflow_dispatch:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  scrape-and-build:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install gensim sumy pandas numpy beautifulsoup4 requests
          pip install rouge-score seaborn matplotlib
          pip install transformers torch
          pip install scikit-learn
          python -c "import nltk; nltk.download('punkt')"

      - name: Create necessary directories
        run: |
          mkdir -p data
          mkdir -p financial_news_summary_website/data

      - name: Run the script
        run: python scrape_and_summarize.py
        
      - name: Check generated files
        run: |
          echo "Files in data directory:"
          ls -la data/ || echo "No data directory found"
          echo "Files in website data directory:"
          ls -la financial_news_summary_website/data/ || echo "No website data directory found"
          
      - name: Commit and push if changes
        run: |
          git config --global user.name 'GitHub Actions Bot'
          git config --global user.email 'actions@github.com'
          git add -A data/ financial_news_summary_website/data/
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Update news data - $(date)"
            git push
            echo "Changes committed and pushed"
          fi
